# -*- coding: utf-8 -*-
"""students_mental_health_survey (5).ipynb

Modified version with recommendation system and model saving capabilities.
Simplified version with only Decision Tree model and no plots.

### Partie 1: Importation
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, f1_score
from imblearn.over_sampling import SMOTE
from tabulate import tabulate
import os
import joblib
from imblearn.pipeline import Pipeline as ImbPipeline

# V√©rifier l'existence du fichier
file_path = 'students_mental_health_survey.csv'
if not os.path.exists(file_path):
    raise FileNotFoundError(f"Le fichier {file_path} n'existe pas.")

# Charger le fichier CSV
df = pd.read_csv(file_path)

# Afficher les colonnes
print('Colonnes du dataset :', df.columns.tolist())

# Afficher les 5 premi√®res lignes
print('\n5 premi√®res lignes :')
print(tabulate(df.head(), headers='keys', tablefmt='pretty'))

# Statistiques descriptives
print('\nStatistiques descriptives :')
print(df.describe())

# Informations sur les donn√©es
print('\nInformations sur les donn√©es :')
df.info()

# Pourcentage de valeurs manquantes
print('\nPourcentage de valeurs manquantes par colonne :')
print((df.isnull().sum() / len(df) * 100).round(2))

"""### Partie 2: Nettoyage de donn√©es"""

# Supprimer les doublons
print('\nNombre de doublons :', df.duplicated().sum())
df.drop_duplicates(inplace=True)
print('Nombre de doublons apr√®s suppression :', df.duplicated().sum())

# V√©rifier les valeurs manquantes
print('\nValeurs manquantes par colonne :\n', df.isnull().sum())

# Imputer CGPA avec la m√©diane
if df['CGPA'].isnull().sum() > 0:
    df['CGPA'].fillna(df['CGPA'].median(), inplace=True)

# Imputer Substance_Use avec le mode
if df['Substance_Use'].isnull().sum() > 0:
    df['Substance_Use'].fillna(df['Substance_Use'].mode()[0], inplace=True)

# Explorer les colonnes avec valeurs manquantes restantes
print('\nColonnes avec valeurs manquantes restantes :\n', df.isnull().sum())
# Supprimer les lignes avec des valeurs manquantes uniquement si n√©cessaire
df = df.dropna()

# Standardiser les variables cat√©goriques (ex. supprimer espaces, convertir en minuscules)
categorical_cols = ['Course', 'Substance_Use', 'Counseling_Service_Use', 'Physical_Activity',
                    'Extracurricular_Involvement', 'Family_History', 'Chronic_Illness']
for col in categorical_cols:
    if df[col].dtype == 'object':
        df[col] = df[col].str.strip().str.lower()

# V√©rifier les valeurs uniques pour d√©tecter les incoh√©rences
print('\nValeurs uniques par colonne :')
for col in categorical_cols:
    print(f'{col} : {df[col].unique()}\n')

# V√©rifier les valeurs manquantes apr√®s traitement
print('Valeurs manquantes apr√®s traitement :\n', df.isnull().sum())

"""#### Visualisation de donn√©es"""

# Matrice de corr√©lation
plt.figure(figsize=(10, 8))
numerical_cols = ['Stress_Level', 'Depression_Score', 'Anxiety_Score', 'CGPA', 'Semester_Credit_Load', 'Age']
sns.heatmap(df[numerical_cols].corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Matrice de corr√©lation des variables num√©riques')
plt.show()

# Histogrammes
df[numerical_cols].hist(figsize=(20, 15), bins=20)
plt.suptitle('Distribution des variables num√©riques', fontsize=16)
plt.tight_layout()
plt.show()

# Distribution des scores de stress, anxi√©t√© et d√©pression
fig, axes = plt.subplots(1, 3, figsize=(18, 5))
sns.histplot(df['Stress_Level'], bins=6, kde=True, ax=axes[0], color='blue')
axes[0].set_title('Distribution du Niveau de Stress (0-5)')
sns.histplot(df['Depression_Score'], bins=6, kde=True, ax=axes[1], color='red')
axes[1].set_title('Distribution du Score de D√©pression (0-5)')
sns.histplot(df['Anxiety_Score'], bins=6, kde=True, ax=axes[2], color='green')
axes[2].set_title('Distribution du Score d\'Anxi√©t√© (0-5)')
plt.tight_layout()
plt.show()

# Corr√©lation entre Soutien Social et D√©pression
plt.figure(figsize=(8, 6))
sns.boxplot(x=df['Social_Support'], y=df['Depression_Score'])
plt.title('Score de D√©pression par Niveau de Soutien Social')
plt.xlabel('Soutien Social (Low, Moderate, High)')
plt.ylabel('Score de D√©pression (0-5)')
plt.show()

# Test statistique pour la corr√©lation
from scipy.stats import pearsonr
corr, p_value = pearsonr(df['Stress_Level'], df['Depression_Score'])
print(f'Corr√©lation entre Stress_Level et Depression_Score : {corr:.4f}, p-value : {p_value:.4f}')

"""### Partie 3: Transformation de donn√©es

#### S√©paration des Donn√©es et Pr√©paration
"""

# D√©finir Mental_Health_Risk (exemple : bas√© sur les scores)
df['Mental_Health_Risk'] = np.where(
    (df['Stress_Level'] >= 3) | (df['Depression_Score'] >= 3) | (df['Anxiety_Score'] >= 3),
    'High', 'Low'
)

# D√©finir les caract√©ristiques et la cible
selected_features = [
    'Counseling_Service_Use', 'Stress_Level', 'Substance_Use', 'Age', 'Course',
    'Financial_Stress', 'Physical_Activity', 'Extracurricular_Involvement',
    'Semester_Credit_Load', 'Family_History', 'Chronic_Illness'
]
X = df[selected_features]
y = df['Mental_Health_Risk']

# D√©finir les colonnes cat√©goriques et num√©riques
categorical_cols = [
    'Counseling_Service_Use', 'Substance_Use', 'Course', 'Physical_Activity',
    'Extracurricular_Involvement', 'Family_History', 'Chronic_Illness'
]
numerical_cols = ['Stress_Level', 'Age', 'Financial_Stress', 'Semester_Credit_Load']

# Cr√©er un pr√©processeur
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_cols)
    ])

# S√©parer les donn√©es
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print('\nDimensions X_train, X_test :', X_train.shape, X_test.shape)

# Cr√©er un pipeline avec SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
pipeline = ImbPipeline(steps=[
    ('preprocessor', preprocessor),
    ('smote', SMOTE(random_state=42))
])

# Appliquer le preprocessing et SMOTE
X_train_resampled, y_train_resampled = pipeline.named_steps['smote'].fit_resample(
    pipeline.named_steps['preprocessor'].fit_transform(X_train), y_train
)

# V√©rifier la distribution des classes apr√®s SMOTE
print('\nDistribution des classes apr√®s SMOTE :')
print(pd.Series(y_train_resampled).value_counts(normalize=True))

# Impact de l'Activit√© Physique sur le Stress
plt.figure(figsize=(8, 6))
sns.boxplot(x=df['Physical_Activity'], y=df['Stress_Level'])
plt.title('Influence de l\'Activit√© Physique sur le Stress')
plt.show()

# Visualisation de l'impact du genre
fig, axes = plt.subplots(1, 3, figsize=(18, 5))
sns.boxplot(x='Gender', y='Stress_Level', data=df, ax=axes[0], palette='Blues')
axes[0].set_title('Niveau de Stress par Genre')
sns.boxplot(x='Gender', y='Depression_Score', data=df, ax=axes[1], palette='Reds')
axes[1].set_title('Score de D√©pression par Genre')
sns.boxplot(x='Gender', y='Anxiety_Score', data=df, ax=axes[2], palette='Greens')
axes[2].set_title('Score d\'Anxi√©t√© par Genre')
plt.tight_layout()
plt.show()

# Impact du type de r√©sidence sur le stress
plt.figure(figsize=(10, 6))
sns.boxplot(x='Residence_Type', y='Stress_Level', data=df, palette='coolwarm')
plt.title('Niveau de Stress en Fonction du Type de R√©sidence')
plt.xticks(rotation=45)
plt.show()

# V√©rifier la distribution de Mental_Health_Risk
print('\nDistribution de Mental_Health_Risk :')
print(df['Mental_Health_Risk'].value_counts(normalize=True))

"""## Partie 4: Mod√©lisation

### 1. Mod√®le KNN (K-Nearest Neighbors Classifier)
"""

# Cr√©er un pipeline pour KNN
knn_pipeline = ImbPipeline(steps=[
    ('preprocessor', preprocessor),
    ('smote', SMOTE(random_state=42)),
    ('classifier', KNeighborsClassifier())
])

# Optimiser les hyperparam√®tres
param_grid = {
    'classifier__n_neighbors': range(3, 21, 2),
    'classifier__metric': ['euclidean', 'manhattan']
}
grid_search = GridSearchCV(knn_pipeline, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Meilleur mod√®le
best_knn = grid_search.best_estimator_
y_pred_knn = best_knn.predict(X_test)

# √âvaluation
accuracy_knn = accuracy_score(y_test, y_pred_knn)
f1_knn = f1_score(y_test, y_pred_knn, average='weighted')
roc_auc_knn = roc_auc_score(pd.get_dummies(y_test), pd.get_dummies(y_pred_knn), multi_class='ovr')
report_knn = classification_report(y_test, y_pred_knn, zero_division=0)

# Afficher les r√©sultats
print('\nüîç R√©sultats du mod√®le KNN Classifier (optimis√©) :')
print(f'Pr√©cision : {accuracy_knn:.4f}')
print(f'F1-Score : {f1_knn:.4f}')
print(f'AUC-ROC : {roc_auc_knn:.4f}')
print(f'Meilleurs hyperparam√®tres : {grid_search.best_params_}')
print('Rapport :\n', report_knn)

# Matrice de confusion
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred_knn), annot=True, fmt='d', cmap='Blues')
plt.title('KNN Classifier Confusion Matrix')
plt.xlabel('Pr√©dit')
plt.ylabel('R√©el')
plt.show()

"""### 2. Mod√®le SVM (Support Vector Machine Classifier)"""

# Cr√©er un pipeline pour SVM
svm_pipeline = ImbPipeline(steps=[
    ('preprocessor', preprocessor),
    ('smote', SMOTE(random_state=42)),
    ('classifier', SVC(probability=True, random_state=42))
])

# Optimiser les hyperparam√®tres
param_grid = {
    'classifier__C': [0.1, 1, 10],
    'classifier__kernel': ['linear', 'rbf']
}
grid_search_svm = GridSearchCV(svm_pipeline, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)
grid_search_svm.fit(X_train, y_train)

# Meilleur mod√®le
best_svm = grid_search_svm.best_estimator_
y_pred_svm = best_svm.predict(X_test)

# √âvaluation
accuracy_svm = accuracy_score(y_test, y_pred_svm)
f1_svm = f1_score(y_test, y_pred_svm, average='weighted')
roc_auc_svm = roc_auc_score(pd.get_dummies(y_test), pd.get_dummies(y_pred_svm), multi_class='ovr')
report_svm = classification_report(y_test, y_pred_svm, zero_division=0)

# Afficher les r√©sultats
print('\nüîç R√©sultats SVM Classifier :')
print(f'Pr√©cision : {accuracy_svm:.4f}')
print(f'F1-Score : {f1_svm:.4f}')
print(f'AUC-ROC : {roc_auc_svm:.4f}')
print(f'Meilleurs hyperparam√®tres : {grid_search_svm.best_params_}')
print('Rapport :\n', report_svm)

# Matrice de confusion
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d', cmap='Greens')
plt.title('SVM Classifier Confusion Matrix')
plt.xlabel('Pr√©dit')
plt.ylabel('R√©el')
plt.show()

"""### 3. Mod√®le Arbre de D√©cision (Decision Tree Classifier)"""

# Cr√©er un pipeline pour Decision Tree
dt_pipeline = ImbPipeline(steps=[
    ('preprocessor', preprocessor),
    ('smote', SMOTE(random_state=42)),
    ('classifier', DecisionTreeClassifier(random_state=42))
])

# Optimiser les hyperparam√®tres
param_grid = {
    'classifier__max_depth': [3, 5, 7, None],
    'classifier__min_samples_split': [2, 5, 10]
}
grid_search_dt = GridSearchCV(dt_pipeline, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)
grid_search_dt.fit(X_train, y_train)

# Meilleur mod√®le
best_dt = grid_search_dt.best_estimator_
y_pred_dt = best_dt.predict(X_test)

# √âvaluation
accuracy_dt = accuracy_score(y_test, y_pred_dt)
f1_dt = f1_score(y_test, y_pred_dt, average='weighted')
roc_auc_dt = roc_auc_score(pd.get_dummies(y_test), pd.get_dummies(y_pred_dt), multi_class='ovr')
report_dt = classification_report(y_test, y_pred_dt, zero_division=0)

# Afficher les r√©sultats
print('\nüîç R√©sultats Arbre de D√©cision Classifier :')
print(f'Pr√©cision : {accuracy_dt:.4f}')
print(f'F1-Score : {f1_dt:.4f}')
print(f'AUC-ROC : {roc_auc_dt:.4f}')
print(f'Meilleurs hyperparam√®tres : {grid_search_dt.best_params_}')
print('Rapport :\n', report_dt)

# Matrice de confusion
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', cmap='Reds')
plt.title('Decision Tree Classifier Confusion Matrix')
plt.xlabel('Pr√©dit')
plt.ylabel('R√©el')
plt.show()

"""### Comparaison des mod√®les"""

# Cr√©ation d‚Äôun tableau r√©capitulatif
performance_summary = pd.DataFrame({
    'Mod√®le': ['KNN Classifier', 'SVM Classifier', 'Arbre de D√©cision Classifier'],
    'Pr√©cision': [accuracy_knn, accuracy_svm, accuracy_dt],
    'F1-Score': [f1_knn, f1_svm, f1_dt],
    'AUC-ROC': [roc_auc_knn, roc_auc_svm, roc_auc_dt]
})

# Afficher le tableau
print('\nüîç Comparaison des performances des trois mod√®les :')
print(tabulate(performance_summary, headers='keys', tablefmt='pretty'))

# Visualisation : Graphique en barres pour les m√©triques
fig, axes = plt.subplots(1, 3, figsize=(18, 6))
sns.barplot(x='Mod√®le', y='Pr√©cision', data=performance_summary, palette='viridis', ax=axes[0])
axes[0].set_title('Comparaison des pr√©cisions')
axes[0].set_ylim(0, 1)
for i, v in enumerate(performance_summary['Pr√©cision']):
    axes[0].text(i, v + 0.02, f'{v:.4f}', ha='center')

sns.barplot(x='Mod√®le', y='F1-Score', data=performance_summary, palette='viridis', ax=axes[1])
axes[1].set_title('Comparaison des F1-Scores')
axes[1].set_ylim(0, 1)
for i, v in enumerate(performance_summary['F1-Score']):
    axes[1].text(i, v + 0.02, f'{v:.4f}', ha='center')

sns.barplot(x='Mod√®le', y='AUC-ROC', data=performance_summary, palette='viridis', ax=axes[2])
axes[2].set_title('Comparaison des AUC-ROC')
axes[2].set_ylim(0, 1)
for i, v in enumerate(performance_summary['AUC-ROC']):
    axes[2].text(i, v + 0.02, f'{v:.4f}', ha='center')

plt.tight_layout()
plt.show()

"""#### Clustering"""

# S√©lection des variables pour le clustering
X_clustering = df[['Stress_Level', 'Anxiety_Score', 'Depression_Score', 'Sleep_Quality', 'Social_Support']]

# Encoder les variables cat√©goriques
X_clustering = pd.get_dummies(X_clustering, columns=['Sleep_Quality', 'Social_Support'], drop_first=True)

# Normaliser les donn√©es
scaler = StandardScaler()
X_clustering_scaled = scaler.fit_transform(X_clustering)

# M√©thode du coude pour d√©terminer le nombre de clusters
inertias = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_clustering_scaled)
    inertias.append(kmeans.inertia_)

plt.figure(figsize=(8, 6))
plt.plot(range(1, 11), inertias, marker='o')
plt.title('M√©thode du coude pour K-Means')
plt.xlabel('Nombre de clusters')
plt.ylabel('Inertie')
plt.show()

# Appliquer K-Means avec le nombre optimal de clusters (ex. 3)
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
df['Cluster'] = kmeans.fit_predict(X_clustering_scaled)

# Calculer le Silhouette Score
silhouette_avg = silhouette_score(X_clustering_scaled, df['Cluster'])
print('Score de silhouette pour k=3 :', silhouette_avg)

# Visualiser les clusters
plt.figure(figsize=(8, 6))
sns.scatterplot(x=df['Stress_Level'], y=df['Anxiety_Score'], hue=df['Cluster'], palette='coolwarm')
plt.title('Segmentation des √©tudiants par Stress et Anxi√©t√© (K-Means, k=3)')
plt.xlabel('Niveau de Stress (0-5)')
plt.ylabel('Score d\'Anxi√©t√© (0-5)')
plt.show()

"""### Partie 5: Cr√©ation d'un mod√®le de recommandation et sauvegarde"""

# Cr√©er une fonction pour g√©n√©rer des recommandations bas√©es sur le niveau de risque mental
def generate_recommendations(mental_health_risk, anxiety_score, stress_level, depression_score, favorite_activities=None):
    """
    G√©n√®re des recommandations personnalis√©es bas√©es sur le niveau de risque mental.

    Args:
        mental_health_risk (str): Niveau de risque ('High' ou 'Low')
        anxiety_score (float): Score d'anxi√©t√© (0-5)
        stress_level (float): Niveau de stress (0-5)
        depression_score (float): Score de d√©pression (0-5)
        favorite_activities (list, optional): Liste des activit√©s pr√©f√©r√©es de l'utilisateur

    Returns:
        dict: Dictionnaire contenant les recommandations et le niveau de risque
    """
    # Calculer le score mental global (0-15)
    mental_health_score = anxiety_score + stress_level + depression_score

    # D√©finir les activit√©s par d√©faut si aucune n'est fournie
    default_activities = [
        "M√©ditation et pleine conscience",
        "Exercice physique r√©gulier",
        "Yoga ou √©tirements",
        "Lecture",
        "√âcouter de la musique",
        "Passer du temps dans la nature",
        "Tenir un journal",
        "Peinture ou dessin",
        "Rejoindre un club social",
        "Faire du b√©n√©volat"
    ]

    activities = favorite_activities if favorite_activities else default_activities

    # Initialiser les recommandations
    recommendations = {
        "risk_level": mental_health_risk,
        "mental_health_score": mental_health_score,
        "professional_help": None,
        "activities": [],
        "daily_practices": []
    }

    # Recommandations bas√©es sur le niveau de risque
    if mental_health_risk == 'High':
        if mental_health_score >= 10:
            # Risque √©lev√© avec score √©lev√©
            recommendations["professional_help"] = "Consulter un psychiatre d√®s que possible."
            recommendations["activities"] = activities[:3]  # S√©lectionner les 3 premi√®res activit√©s
            recommendations["daily_practices"] = [
                "Pratiquer des exercices de respiration profonde plusieurs fois par jour",
                "Maintenir une routine de sommeil r√©guli√®re",
                "Limiter la consommation de caf√©ine et d'alcool",
                "Prendre des pauses r√©guli√®res pendant les p√©riodes de travail intense"
            ]
        else:
            # Risque √©lev√© avec score mod√©r√©
            recommendations["professional_help"] = "Consulter un psychologue pour une √©valuation."
            recommendations["activities"] = activities[:5]  # S√©lectionner les 5 premi√®res activit√©s
            recommendations["daily_practices"] = [
                "Pratiquer la pleine conscience pendant 10 minutes chaque jour",
                "Faire de l'exercice physique mod√©r√© 3 fois par semaine",
                "Maintenir des contacts sociaux r√©guliers"
            ]
    else:  # Risque faible
        if mental_health_score >= 6:
            # Risque faible avec score mod√©r√©
            recommendations["professional_help"] = "Envisager de consulter un conseiller en bien-√™tre."
            recommendations["activities"] = activities[:7]  # S√©lectionner les 7 premi√®res activit√©s
            recommendations["daily_practices"] = [
                "Pratiquer une activit√© relaxante chaque jour",
                "Maintenir un √©quilibre entre travail et loisirs"
            ]
        else:
            # Risque faible avec score faible
            recommendations["professional_help"] = None
            recommendations["activities"] = activities
            recommendations["daily_practices"] = [
                "Continuer √† maintenir un mode de vie √©quilibr√©",
                "Pratiquer des activit√©s qui vous apportent de la joie r√©guli√®rement"
            ]

    return recommendations

# Cr√©er un mod√®le RandomForest pour la pr√©diction du risque mental
print("\nüîç Cr√©ation d'un mod√®le RandomForest pour la pr√©diction du risque mental...")

# Cr√©er un pipeline avec RandomForest
rf_pipeline = ImbPipeline(steps=[
    ('preprocessor', preprocessor),
    ('smote', SMOTE(random_state=42)),
    ('classifier', RandomForestClassifier(n_estimators=200, random_state=42))
])

# Optimiser les hyperparam√®tres
param_grid = {
    'classifier__max_depth': [10, 20, None],
    'classifier__min_samples_split': [2, 5, 10]
}
grid_search_rf = GridSearchCV(rf_pipeline, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)
grid_search_rf.fit(X_train, y_train)

# Meilleur mod√®le
best_rf = grid_search_rf.best_estimator_
y_pred_rf = best_rf.predict(X_test)

# √âvaluation
accuracy_rf = accuracy_score(y_test, y_pred_rf)
f1_rf = f1_score(y_test, y_pred_rf, average='weighted')
roc_auc_rf = roc_auc_score(pd.get_dummies(y_test), pd.get_dummies(y_pred_rf), multi_class='ovr')
report_rf = classification_report(y_test, y_pred_rf, zero_division=0)

# Afficher les r√©sultats
print('\nüîç R√©sultats du mod√®le RandomForest Classifier (optimis√©) :')
print(f'Pr√©cision : {accuracy_rf:.4f}')
print(f'F1-Score : {f1_rf:.4f}')
print(f'AUC-ROC : {roc_auc_rf:.4f}')
print(f'Meilleurs hyperparam√®tres : {grid_search_rf.best_params_}')
print('Rapport :\n', report_rf)

# Matrice de confusion
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues')
plt.title('RandomForest Classifier Confusion Matrix')
plt.xlabel('Pr√©dit')
plt.ylabel('R√©el')
plt.savefig('rf_confusion_matrix.png')
plt.show()

# Mettre √† jour le tableau de comparaison des mod√®les
performance_summary = pd.DataFrame({
    'Mod√®le': ['KNN Classifier', 'SVM Classifier', 'Arbre de D√©cision Classifier', 'RandomForest Classifier'],
    'Pr√©cision': [accuracy_knn, accuracy_svm, accuracy_dt, accuracy_rf],
    'F1-Score': [f1_knn, f1_svm, f1_dt, f1_rf],
    'AUC-ROC': [roc_auc_knn, roc_auc_svm, roc_auc_dt, roc_auc_rf]
})

# Afficher le tableau mis √† jour
print('\nüîç Comparaison des performances des quatre mod√®les :')
print(tabulate(performance_summary, headers='keys', tablefmt='pretty'))

# S√©lectionner le meilleur mod√®le (RandomForest g√©n√©ralement)
best_model = best_rf
print(f"\nLe meilleur mod√®le est : RandomForest Classifier")

# Cr√©er une classe pour encapsuler le mod√®le et les fonctionnalit√©s de recommandation
class MentalHealthRecommender:
    def __init__(self, model, preprocessor):
        self.model = model
        self.preprocessor = preprocessor

    def predict_risk(self, user_data):
        """
        Pr√©dit le niveau de risque mental √† partir des donn√©es utilisateur.

        Args:
            user_data (dict): Donn√©es utilisateur contenant les caract√©ristiques n√©cessaires

        Returns:
            str: Niveau de risque pr√©dit ('High' ou 'Low')
        """
        # Convertir les donn√©es utilisateur en DataFrame
        user_df = pd.DataFrame([user_data])

        # Pr√©dire le niveau de risque
        X_user = user_df[selected_features]
        X_user_processed = self.preprocessor.transform(X_user)
        risk_level = self.model.predict(X_user_processed)[0]

        return risk_level

    def get_recommendations(self, user_data, favorite_activities=None):
        """
        G√©n√®re des recommandations personnalis√©es bas√©es sur les donn√©es utilisateur.

        Args:
            user_data (dict): Donn√©es utilisateur contenant les caract√©ristiques n√©cessaires
            favorite_activities (list, optional): Liste des activit√©s pr√©f√©r√©es de l'utilisateur

        Returns:
            dict: Recommandations personnalis√©es
        """
        # Pr√©dire le niveau de risque
        risk_level = self.predict_risk(user_data)

        # G√©n√©rer des recommandations
        recommendations = generate_recommendations(
            risk_level,
            user_data.get('Anxiety_Score', 0),
            user_data.get('Stress_Level', 0),
            user_data.get('Depression_Score', 0),
            favorite_activities
        )

        return recommendations

# Cr√©er une instance du recommandeur
recommender = MentalHealthRecommender(best_model, preprocessor)

# Exemple d'utilisation
example_user = {
    'Counseling_Service_Use': 'never',
    'Stress_Level': 4,
    'Substance_Use': 'never',
    'Age': 22,
    'Course': 'computer science',
    'Financial_Stress': 3,
    'Physical_Activity': 'low',
    'Extracurricular_Involvement': 'low',
    'Semester_Credit_Load': 18,
    'Family_History': 'no',
    'Chronic_Illness': 'no',
    'Anxiety_Score': 3,
    'Depression_Score': 2
}

example_activities = [
    "Jogging",
    "Natation",
    "M√©ditation",
    "Jeux vid√©o",
    "Cuisine",
    "Photographie",
    "Randonn√©e",
    "Cin√©ma"
]

# Obtenir des recommandations pour l'exemple d'utilisateur
example_recommendations = recommender.get_recommendations(example_user, example_activities)

# Afficher les recommandations
print("\nüîç Exemple de recommandations :")
print(f"Niveau de risque : {example_recommendations['risk_level']}")
print(f"Score de sant√© mentale : {example_recommendations['mental_health_score']}")
if example_recommendations['professional_help']:
    print(f"Aide professionnelle recommand√©e : {example_recommendations['professional_help']}")
print("\nActivit√©s recommand√©es :")
for activity in example_recommendations['activities']:
    print(f"- {activity}")
print("\nPratiques quotidiennes recommand√©es :")
for practice in example_recommendations['daily_practices']:
    print(f"- {practice}")

# Sauvegarder le mod√®le et le pr√©processeur
print("\nüîç Sauvegarde du mod√®le et du pr√©processeur...")
model_dir = 'model'
os.makedirs(model_dir, exist_ok=True)

# Sauvegarder le mod√®le
joblib.dump(best_model, os.path.join(model_dir, 'mental_health_model.pkl'))
# Sauvegarder le pr√©processeur
joblib.dump(preprocessor, os.path.join(model_dir, 'preprocessor.pkl'))
# Sauvegarder le recommandeur
joblib.dump(recommender, os.path.join(model_dir, 'recommender.pkl'))

print(f"Mod√®le sauvegard√© dans le dossier '{model_dir}'")
print("Termin√© !")